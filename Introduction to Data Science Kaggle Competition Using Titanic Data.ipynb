{
 "metadata": {
  "name": "Introduction to Data Science Kaggle Competition Using Titanic Data"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Introduction to Data Science Kaggle Competition Using Titanic Data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Environment Setup"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First thing, we'll need a Python environment suitable for scientific and statistical computing. Assuming you already have Python installed (no? Well then get it! Python 2.7 is recommended), we'll need three packages. You should install each in the order they appear here:\n",
      "\n",
      "* numpy - (pronounced num-pie) Powerful numerical arrays. A foundational package for the two packages below.\n",
      "* scipy - (sigh-pie) Scientific, mathematical, and engineering package\n",
      "* scikit-learn - Easy to use machine learning library\n",
      " \n",
      "Note: I needed to upgrade the version of Numpy on my Ubuntu 12.04 Scikit-learn VM in order to get this tutorial to work."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "pip install numpy --upgrade"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now check program versions below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Check program versions\n",
      "import sklearn as sk\n",
      "import numpy as np\n",
      "import IPython\n",
      "\n",
      "print sk.__version__\n",
      "print np.__version__\n",
      "print IPython.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.14.1\n",
        "1.8.1\n",
        "0.13.2\n"
       ]
      }
     ],
     "prompt_number": 223
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Prepare the Data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Munge the Training Dataset"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "First, we must load the training dataset. We assume it is located in the train.csv file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import numpy as np\n",
      "with open('Data/titanic_train.csv', 'rb') as csvfile:\n",
      "    titanic_reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
      "    \n",
      "    # Header contains feature names\n",
      "    row = titanic_reader.next()\n",
      "    train_feature_names = np.array(row)\n",
      "    \n",
      "    # Load dataset, and target classes\n",
      "    titanic_train_X, titanic_train_y = [], []\n",
      "    for row in titanic_reader:  \n",
      "        titanic_train_X.append(row)\n",
      "        titanic_train_y.append(row[1]) # The target value is \"survived\"\n",
      "    \n",
      "    titanic_train_X = np.array(titanic_train_X)\n",
      "    titanic_train_y = np.array(titanic_train_y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_feature_names\n",
      "print titanic_train_X[0]\n",
      "print titanic_train_y[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
        " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n",
        "['1' '0' '3' 'Braund, Mr. Owen Harris' 'male' '22' '1' '0' 'A/5 21171'\n",
        " '7.25' '' 'S']\n",
        "0\n"
       ]
      }
     ],
     "prompt_number": 225
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Keep only class (1st,2nd,3rd), sex (male, female), age (float)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we keep the class, the sex and the age\n",
      "titanic_train_X = titanic_train_X[:, [2, 4, 5]]\n",
      "train_feature_names = train_feature_names[[2, 4, 5]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_feature_names\n",
      "print titanic_train_X[5], titanic_train_y[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Pclass' 'Sex' 'Age']\n",
        "['3' 'male' ''] 0\n"
       ]
      }
     ],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We have missing values for age\n",
      "# Assign the mean value\n",
      "ages = titanic_train_X[:, 2]\n",
      "#print ages\n",
      "mean_age = np.mean(titanic_train_X[ages != '', 2].astype(np.float))\n",
      "#print mean_age\n",
      "titanic_train_X[titanic_train_X[:, 2] == '', 2] = mean_age\n",
      "#print titanic_train_X[:, 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 228
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_feature_names\n",
      "print titanic_train_X[5], titanic_train_y[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Pclass' 'Sex' 'Age']\n",
        "['3' 'male' '29.6991176471'] 0\n"
       ]
      }
     ],
     "prompt_number": 229
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Class and sex are categorical classes. Sex can be converted to a binary value (0=female,1=male):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Encode sex \n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "enc = LabelEncoder()\n",
      "label_encoder = enc.fit(titanic_train_X[:, 1])\n",
      "print \"Categorical classes:\", label_encoder.classes_\n",
      "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
      "print \"Integer classes:\", integer_classes\n",
      "t = label_encoder.transform(titanic_train_X[:, 1])\n",
      "titanic_train_X[:, 1] = t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Categorical classes: ['female' 'male']\n",
        "Integer classes: [0 1]\n"
       ]
      }
     ],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_feature_names\n",
      "print titanic_train_X[5], titanic_train_y[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Pclass' 'Sex' 'Age']\n",
        "['3' '1' '29.6991176471'] 0\n"
       ]
      }
     ],
     "prompt_number": 231
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we have to convert the class. Since we have three different classes, we cannot convert to binary values (and using 0/1/2 values would imply an order, something we do not want). We use OneHotEncoder to get three different attributes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "enc = LabelEncoder()\n",
      "label_encoder = enc.fit(titanic_train_X[:, 0])\n",
      "print \"Categorical classes:\", label_encoder.classes_\n",
      "integer_classes = label_encoder.transform(label_encoder.classes_).reshape(3, 1)\n",
      "print \"Integer classes:\", integer_classes\n",
      "enc = OneHotEncoder()\n",
      "one_hot_encoder = enc.fit(integer_classes)\n",
      "# First, convert clases to 0-(N-1) integers using label_encoder\n",
      "num_of_rows = titanic_train_X.shape[0]\n",
      "t = label_encoder.transform(titanic_train_X[:, 0]).reshape(num_of_rows, 1)\n",
      "# Second, create a sparse matrix with three columns, each one indicating if the instance belongs to the class\n",
      "new_features = one_hot_encoder.transform(t)\n",
      "# Add the new features to titanix_X\n",
      "titanic_train_X = np.concatenate([titanic_train_X, new_features.toarray()], axis = 1)\n",
      "#Eliminate converted columns\n",
      "titanic_train_X = np.delete(titanic_train_X, [0], 1)\n",
      "# Update feature names\n",
      "train_feature_names = ['sex', 'age', 'first_class', 'second_class', 'third_class']\n",
      "# Convert to numerical values\n",
      "titanic_train_X = titanic_train_X.astype(float)\n",
      "titanic_train_y = titanic_train_y.astype(float)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Categorical classes: ['1' '2' '3']\n",
        "Integer classes: [[0]\n",
        " [1]\n",
        " [2]]\n"
       ]
      }
     ],
     "prompt_number": 232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train_feature_names\n",
      "print titanic_train_X[5], titanic_train_y[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['sex', 'age', 'first_class', 'second_class', 'third_class']\n",
        "[  1.          29.69911765   0.           0.           1.        ] 0.0\n"
       ]
      }
     ],
     "prompt_number": 233
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Munge the Test Dataset"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Now, we must load the test dataset. We assume it is located in the test.csv file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "with open('Data/titanic_test.csv', 'rb') as csvfile:\n",
      "    titanic_reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
      "    \n",
      "    # Header contains feature names\n",
      "    row = titanic_reader.next()\n",
      "    test_feature_names = np.array(row)\n",
      "    \n",
      "    # Load dataset, and target classes\n",
      "    titanic_test_X = []\n",
      "    for row in titanic_reader:  \n",
      "        titanic_test_X.append(row)\n",
      "    \n",
      "    titanic_test_X = np.array(titanic_test_X)\n",
      "    test_passender_ids = titanic_test_X[:,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 234
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_feature_names\n",
      "print titanic_test_X[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['PassengerId' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare'\n",
        " 'Cabin' 'Embarked']\n",
        "['892' '3' 'Kelly, Mr. James' 'male' '34.5' '0' '0' '330911' '7.8292' ''\n",
        " 'Q']\n"
       ]
      }
     ],
     "prompt_number": 235
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Keep only class (1st,2nd,3rd), age (float), and sex (male, female)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we keep the class, the sex and the age\n",
      "titanic_test_X = titanic_test_X[:, [1, 3, 4]]\n",
      "test_feature_names = test_feature_names[[1, 3, 4]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_feature_names\n",
      "print titanic_test_X[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Pclass' 'Sex' 'Age']\n",
        "['3' 'male' '']\n"
       ]
      }
     ],
     "prompt_number": 237
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Now, we have to convert the class. Since we have three different classes, we cannot convert to binary values (and using 0/1/2 values would imply an order, something we do not want). We use OneHotEncoder to get three different attributes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We have missing values for age\n",
      "# Assign the mean value\n",
      "ages = titanic_test_X[:, 2]\n",
      "#print ages\n",
      "mean_age = np.mean(titanic_test_X[ages != '', 2].astype(np.float))\n",
      "#print mean_age\n",
      "titanic_test_X[titanic_test_X[:, 2] == '', 2] = mean_age\n",
      "#print titanic_test_X[:, 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_feature_names\n",
      "print titanic_test_X[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Pclass' 'Sex' 'Age']\n",
        "['3' 'male' '30.2725903614']\n"
       ]
      }
     ],
     "prompt_number": 239
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Class and sex are categorical classes. Sex can be converted to a binary value (0=female,1=male):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "# Encode sex \n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "enc = LabelEncoder()\n",
      "label_encoder = enc.fit(titanic_test_X[:, 1])\n",
      "print \"Categorical classes:\", label_encoder.classes_\n",
      "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
      "print \"Integer classes:\", integer_classes\n",
      "t = label_encoder.transform(titanic_test_X[:, 1])\n",
      "titanic_test_X[:, 1] = t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Categorical classes: ['female' 'male']\n",
        "Integer classes: [0 1]\n"
       ]
      }
     ],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_feature_names\n",
      "print titanic_test_X[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Pclass' 'Sex' 'Age']\n",
        "['3' '1' '30.2725903614']\n"
       ]
      }
     ],
     "prompt_number": 241
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we have to convert the class. Since we have three different classes, we cannot convert to binary values (and using 0/1/2 values would imply an order, something we do not want). We use OneHotEncoder to get three different attributes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "enc = LabelEncoder()\n",
      "label_encoder = enc.fit(titanic_test_X[:, 0])\n",
      "print \"Categorical classes:\", label_encoder.classes_\n",
      "integer_classes = label_encoder.transform(label_encoder.classes_).reshape(3, 1)\n",
      "print \"Integer classes:\", integer_classes\n",
      "enc = OneHotEncoder()\n",
      "one_hot_encoder = enc.fit(integer_classes)\n",
      "# First, convert clases to 0-(N-1) integers using label_encoder\n",
      "num_of_rows = titanic_test_X.shape[0]\n",
      "t = label_encoder.transform(titanic_test_X[:, 0]).reshape(num_of_rows, 1)\n",
      "# Second, create a sparse matrix with three columns, each one indicating if the instance belongs to the class\n",
      "new_features = one_hot_encoder.transform(t)\n",
      "# Add the new features to titanix_X\n",
      "titanic_test_X = np.concatenate([titanic_test_X, new_features.toarray()], axis = 1)\n",
      "#Eliminate converted columns\n",
      "titanic_test_X = np.delete(titanic_test_X, [0], 1)\n",
      "# Update feature names\n",
      "test_feature_names = ['sex', 'age', 'first_class', 'second_class', 'third_class']\n",
      "# Convert to numerical values\n",
      "titanic_test_X = titanic_test_X.astype(float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Categorical classes: ['1' '2' '3']\n",
        "Integer classes: [[0]\n",
        " [1]\n",
        " [2]]\n"
       ]
      }
     ],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_feature_names\n",
      "print titanic_test_X[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['sex', 'age', 'first_class', 'second_class', 'third_class']\n",
        "[  1.          30.27259036   0.           0.           1.        ]\n"
       ]
      }
     ],
     "prompt_number": 243
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "First Submission Using Decision Trees"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv as csv\n",
      "from sklearn import tree\n",
      "#create and train the decision tree\n",
      "\n",
      "dt = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=5)\n",
      "dt.fit(titanic_train_X, titanic_train_y)\n",
      "\n",
      "output = dt.predict(titanic_test_X).astype(int)\n",
      "\n",
      "predictions_file = open(\"Data/decision_tree_submission.csv\", \"wb\")\n",
      "open_file_object = csv.writer(predictions_file)\n",
      "open_file_object.writerow([\"PassengerId\",\"Survived\"])\n",
      "open_file_object.writerows(zip(test_passender_ids, output))\n",
      "predictions_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 244
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Evaluation and Cross-Validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's say we wanted to try out sklearn's gradient boosting machine instead of a random forest. Or maybe some simple linear models. It's easy enough to import these methods from sklearn and generate submission files, but it's not so easy to compare their performance. It's not practical to upload a new submission every time we make a change to the model - we'll need a way to test things out locally, and we'll need two things in order to do that:\n",
      "\n",
      "1. An evaluation function\n",
      "2. Cross validation\n",
      "\n",
      "You'll always need some kind of evaluation function to determine how your models are performing. Ideally, these would be identical to the evaluation metric that Kaggle is using to score your entry."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy as sp\n",
      "def llfun(act, pred):\n",
      "    epsilon = 1e-15\n",
      "    pred = sp.maximum(epsilon, pred)\n",
      "    pred = sp.minimum(1-epsilon, pred)\n",
      "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
      "    ll = ll * -1.0/len(act)\n",
      "    return ll"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 245
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we'll need data to test our models against. When you submitted your first Kaggle competition entry earlier in this tutorial, Kaggle compared (using log-loss) your answers to the actual real world results (the \"ground truth\") associated with the test data set. Without access to those answers, how can we actually test our models locally? Cross-validation to the rescue!\n",
      "\n",
      "Cross-validation is a simple technique that basically grabs a chunk of the training data and holds it in reserve while the model is trained on the remainder of the data set. In case you haven't realized it yet, sklearn is totally awesome and is here to help. It has built in tools to generate cross validation sets. The sklearn documentation has a lot of great information on [cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html).\n",
      "\n",
      "The code below creates 10 cross-validation sets (called folds), each with 10% of the training data set held in reserve, and tests our decision tree model against that withheld data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "import numpy as np\n",
      "\n",
      "target = titanic_train_y\n",
      "#print target\n",
      "train = titanic_train_X\n",
      "#print train\n",
      "\n",
      "#Simple K-Fold cross validation. 10 folds.\n",
      "cv = cross_validation.KFold(len(train), n_folds=10, indices=False)\n",
      "\n",
      "#iterate through the training and test cross validation segments and\n",
      "#run the classifier on each one, aggregating the results into a list\n",
      "results = []\n",
      "for traincv, testcv in cv:\n",
      "    probas = dt.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\n",
      "    results.append(llfun(target[testcv], [x[1] for x in probas]) )\n",
      "print results\n",
      "#print out the mean of the cross-validated results\n",
      "print \"Results: \" + str( np.array(results).mean() )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.51363473822508676, 0.44094320704996726, 0.45636258733325269, 0.79388840072338218, 0.41742147087015741, 0.80909994510383809, 0.46782678625999241, 0.45745995566571995, 0.33537994389561848, 0.4187991746713306]\n",
        "Results: 0.51108162098\n"
       ]
      }
     ],
     "prompt_number": 246
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Second Submission Using Random Forests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "#create and train the random forest\n",
      "#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
      "rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
      "rf.fit(titanic_train_X, titanic_train_y)\n",
      "\n",
      "output = rf.predict(titanic_test_X).astype(int)\n",
      "\n",
      "predictions_file = open(\"Data/random_forest_submission_forest.csv\", \"wb\")\n",
      "open_file_object = csv.writer(predictions_file)\n",
      "open_file_object.writerow([\"PassengerId\",\"Survived\"])\n",
      "open_file_object.writerows(zip(test_passender_ids, output))\n",
      "predictions_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 247
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code below creates 10 cross-validation sets (called folds), each with 10% of the training data set held in reserve, and tests our random forest model against that withheld data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "import numpy as np\n",
      "\n",
      "target = titanic_train_y\n",
      "#print target\n",
      "train = titanic_train_X\n",
      "#print train\n",
      "\n",
      "#Simple K-Fold cross validation. 10 folds.\n",
      "cv = cross_validation.KFold(len(train), n_folds=10, indices=False)\n",
      "\n",
      "#iterate through the training and test cross validation segments and\n",
      "#run the classifier on each one, aggregating the results into a list\n",
      "results = []\n",
      "for traincv, testcv in cv:\n",
      "    probas = rf.fit(train[traincv], target[traincv]).predict_proba(train[testcv])\n",
      "    results.append(llfun(target[testcv], [x[1] for x in probas]) )\n",
      "print results\n",
      "#print out the mean of the cross-validated results\n",
      "print \"Results: \" + str( np.array(results).mean() )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.91756397017062674, 1.5298777562587755, 2.6690763676173463, 1.2408826020042059, 1.8460715068604374, 0.80797771573495591, 1.5261826164338885, 1.6235549721779372, 0.38381084118297787, 1.1453848595794254]\n",
        "Results: 1.3690383208\n"
       ]
      }
     ],
     "prompt_number": 248
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 248
    }
   ],
   "metadata": {}
  }
 ]
}